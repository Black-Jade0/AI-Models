{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Black-Jade0/AI-Models/blob/master/Real_time_eye_tracking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import dlib\n",
        "import numpy as np\n",
        "\n",
        "# Load the pre-trained face detector and shape predictor from dlib\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
        "\n",
        "# Eye indices from the 68 landmarks model\n",
        "LEFT_EYE_START = 36\n",
        "LEFT_EYE_END = 41\n",
        "RIGHT_EYE_START = 42\n",
        "RIGHT_EYE_END = 47\n",
        "\n",
        "def eye_aspect_ratio(eye):\n",
        "    # Compute the euclidean distances between the two sets of vertical eye landmarks (x, y)-coordinates\n",
        "    A = np.linalg.norm(eye[1] - eye[5])\n",
        "    B = np.linalg.norm(eye[2] - eye[4])\n",
        "\n",
        "    # Compute the euclidean distance between the horizontal eye landmark (x, y)-coordinates\n",
        "    C = np.linalg.norm(eye[0] - eye[3])\n",
        "\n",
        "    # The eye aspect ratio (EAR)\n",
        "    ear = (A + B) / (2.0 * C)\n",
        "    return ear\n",
        "\n",
        "def get_eye_points(shape, eye_start, eye_end):\n",
        "    # Get the eye points from the facial landmarks\n",
        "    eye_points = shape[eye_start:eye_end + 1]\n",
        "    return eye_points\n",
        "\n",
        "def is_looking_away(left_ear, right_ear, threshold=0.2):\n",
        "    # If the EAR is less than a threshold, the user is potentially not looking straight (attention deviation)\n",
        "    return left_ear < threshold or right_ear < threshold\n",
        "\n",
        "# Start capturing the video feed from the webcam\n",
        "cap = cv2.VideoCapture(1)\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Detect faces in the frame\n",
        "    faces = detector(gray)\n",
        "\n",
        "    for face in faces:\n",
        "        # Predict facial landmarks\n",
        "        landmarks = predictor(gray, face)\n",
        "        landmarks = np.array([[p.x, p.y] for p in landmarks.parts()])\n",
        "\n",
        "        # Get the eye points\n",
        "        left_eye_points = get_eye_points(landmarks, LEFT_EYE_START, LEFT_EYE_END)\n",
        "        right_eye_points = get_eye_points(landmarks, RIGHT_EYE_START, RIGHT_EYE_END)\n",
        "\n",
        "        # Compute the EAR for both eyes\n",
        "        left_ear = eye_aspect_ratio(left_eye_points)\n",
        "        right_ear = eye_aspect_ratio(right_eye_points)\n",
        "\n",
        "        # Draw the eye landmarks for visualization\n",
        "        for point in left_eye_points:\n",
        "            cv2.circle(frame, tuple(point), 2, (0, 255, 0), 1)\n",
        "        for point in right_eye_points:\n",
        "            cv2.circle(frame, tuple(point), 2, (0, 255, 0), 1)\n",
        "\n",
        "        # Check if the user is looking away\n",
        "        if is_looking_away(left_ear, right_ear):\n",
        "            cv2.putText(frame, \"Looking Away!\", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "        else:\n",
        "            cv2.putText(frame, \"Looking Forward\", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "\n",
        "    # Display the result\n",
        "    cv2.imshow(\"Eye Tracking\", frame)\n",
        "\n",
        "    # Break the loop on 'q' key press\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release the camera and close all windows\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "dia0cFtqWJNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zOse6LzUY67t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}